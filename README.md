# Introduction to Digital Forensics - Assignment 1
### Data used ðŸ’½
The group collected 100 listings in total from the Vice Market on the dark web.

The focus was to collect data in a objective manner. This was done by choosing random listings listed on the site that were recommended. The listings recommended were most often from sellers with many reviews and sales. These sellers are the good and reliable sellers on the site.

The data is checked for duplicates before generating the graphs. Data collected contains a column called 'Listing ID'. This is a unique identifier for a listing and it generated from the URL in the Excel file. In this Notebook we check whether there are duplicate Listing ID's in the dataset and point out where the duplicates are located so we can exchange them for new, non duplicated listings, to improve the quality of the data and analysis.

### Results generated in this Jupyter Notebook
- Duplicate listings in the dataset
- Top 10 sellers based on amount of listings on Vice City Market
- Top 10 highest priced listings on Vice City Market
- Ratio of legal/illegal/depends listings
- Top 3 categories with the most listings

### Other assignment questions answered in this Jupyter Notebook
- Most suprising products/posts
- Vendors investigated
- Three vendors the police should investigate

### Made by group 1:
- Mark Boom         s2552469
- Tom Essers        s2484765 
- Simge Bilen       s2532239
- Baran Gulbey      s2616394
- Jelmer Hofman     s2460653
- Stijn Schuurman   s2620162